{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai.organization = \"org-******\"\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 LLM and Chat Models Base 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n\\nAs of now, there are 8 planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. However, there may be more planets in our solar system that have not yet been discovered.',\n",
       " 'There are eight recognized planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\") \n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "# llm = OpenAI( open_api_key=\"sk-zzz\")\n",
    "# chat = ChatOpenAI(open_api_key=\"sk-zzz\")\n",
    "\n",
    "a = llm.predict(\"How many planets are there?\") # text-davinch\n",
    "b = chat.predict(\"How many planets are there?\") # gpt-3\n",
    "\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Predcit Message Model 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    temperature=0.1 # 모델에게 창의성 부여, 숫자가 낮을수록 모델의 창의성이 낮음\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao! La distanza tra il Messico e la Thailandia è di circa 16.000 chilometri. Il mio nome è Paolo. Posso aiutarti con altre domande di geografia?')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# message를 predict\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "# HumanMessage = 인간메시지, AIMessage = AI에 의해 보내지는 것, SystemMessage  = LLM에 설정들을 제공하기 위한 메시지\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a geography expert. And you only reply in Italian.\",\n",
    "                  # You are a geography expert. And you only reply in {language}.\n",
    "                  ), # AI에 일종의 기본 설정, 기본 값, 기본 context 설정 (가상의 시나리오)\n",
    "    AIMessage(content=\"Ciao, mi chiamo Paolo!\"), # string을 미리 만들어 두고, 일종의 가상 대화를 만듦\n",
    "    # AI에게 자격을 부여해 주는 메시지\n",
    "    # Ciao, mi chiamo {name}!\n",
    "    HumanMessage(content=\"What is the distence between Mexico an Thailand. Also, What is your name?\",),\n",
    "    # 내가 사용자로서 질문을 함\n",
    "    # What is the distence between {country_a} an {country_b}. Also, What is your name?\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the distence between Mexico an Thailand'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"What is the distence between {country_a} an {country_b}\",\n",
    "                                        )\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "template.format(country_a=\"Mexico\", country_b=\"Thailand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 9,500 miles (15,300 kilometers) when measured in a straight line.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "template = PromptTemplate.from_template(\"What is the distence between {country_a} an {country_b}\",\n",
    "                                        )\n",
    "prompt = template.format(country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Γεια σας! Η απόσταση μεταξύ του Μεξικού και της Ταϊλάνδης είναι περίπου 16.000 χιλιόμετρα. Το όνομά μου είναι Σωκράτης. Πώς μπορώ να βοηθήσω;')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "    (\"ai\", \"Ciao, mi chiamo {name}!\"),\n",
    "    (\"human\", \"What is the distence between {country_a} an {country_b}. Also, What is your name?\",),\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    language=\"Greek\",\n",
    "    name=\"Socrates\",\n",
    "    country_a=\"Mexico\",\n",
    "    country_b=\"Thailand\"\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Output Parser and LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt > Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# Output Parser가 필요한 이유는 LLM의 응답을 변형해야 할 때가 있기 때문\n",
    "# LLM은 텍스트 응답이기 때문에 list 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    # OutputParser는 parse라는 함수를 지정해야함\n",
    "    def parse(self, text): # text 매개변수를 통해 전체 텍스트를 입력 받음\n",
    "        items =  text.strip().split(\",\") # .strip() = 공백 제거\n",
    "        return list(map(str.strip,items)) # list를 반환하기 전 먼저 items의 각 요소에 작업해 줌\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(\"Hello, how, are, you\")\n",
    "# ['Hello', 'how', 'are', 'you']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune, Pluto')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items}. Do NOT reply with anything else.\",),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items=10, # 10개 이하\n",
    "    question=\"What are the planets?\"\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Red',\n",
       " 'blue',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'orange',\n",
       " 'purple',\n",
       " 'pink',\n",
       " 'black',\n",
       " 'white',\n",
       " 'brown']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items}. Do NOT reply with anything else.\",),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items=10, # 10개 이하\n",
    "    question=\"What are the colors?\"\n",
    ")\n",
    "\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mercury', 'venus', 'earth', 'mars', 'jupiter', 'saturn', 'uranus', 'neptune']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase. Do NOT reply with anything else.\",),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items=10, # 10개 이하\n",
    "    question=\"What are the planets?\"\n",
    ")\n",
    "\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['피카츄', '꼬부기', '파이리', '이상해씨']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain = 모든 요소를 합쳐주는 역할\n",
    "# 합쳐진 요소들은 하나의 chain으로 실행. 하나하나 순서대로, result를 반환할 때까지\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "# chat의 input type은 string 한 개, 메시지의 list 또는 promptValue\n",
    "# ChatModel은 ChatMessage를 반환하고, 그 값은 Ouput Parser에게 전해짐\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    # OutputParser는 parse라는 함수를 지정해야함\n",
    "    def parse(self, text): # text 매개변수를 통해 전체 텍스트를 입력 받음\n",
    "        items =  text.strip().split(\",\") # .strip() = 공백 제거\n",
    "        return list(map(str.strip,items)) # list를 반환하기 전 먼저 items의 각 요소에 작업해 줌\n",
    "# Output Parser는 LLM 이나 ChatModel의 반환타입과 동일함\n",
    "# = Output Parser의 Input type = ChatMessage's input type\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items}. Do NOT reply with anything else.\",),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = template | chat | CommaOutputParser()\n",
    "# template에 chian.invoke가 전달되고, chat에 template 가 전달되고 Chat의 반환값은 OutputParser에게 전달됨\n",
    "# Chain은 단지 component의 그룹 혹은 나열\n",
    "# component들은 입력값을 받아서 출력값을 반환함\n",
    "\n",
    "chain.invoke({\n",
    "    \"max_items\":5,\n",
    "    \"question\":\"포켓몬에는 뭐가 있어?\"\n",
    "})\n",
    "# Prompt의 type은 dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Chaining Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatAnthropic, ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, \n",
    "                  streaming=True, \n",
    "                  callbacks=[StreamingStdOutCallbackHandler()])\n",
    "# streaming은 우리가 model의 응답이 생성되는걸 볼 수 있게 해줌\n",
    "# callbacks 덕분에 콘솔에서 응답의 진행을 볼 수 있게 됨\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to fine ingredients.\"),\n",
    "    (\"human\", \"I want to cook {cuisine} food.\"),\n",
    "])\n",
    "\n",
    "chef_chain = chef_prompt | chat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! Let's make a delicious and easy Chicken Tikka Masala. Here's the recipe:\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb boneless, skinless chicken breasts, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt\n",
      "- 2 tablespoons lemon juice\n",
      "- 2 tablespoons vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 3 cloves garlic, minced\n",
      "- 1 tablespoon ginger, minced\n",
      "- 1 can (14 oz) tomato sauce\n",
      "- 1 tablespoon garam masala\n",
      "- 1 teaspoon ground cumin\n",
      "- 1 teaspoon ground coriander\n",
      "- 1 teaspoon paprika\n",
      "- 1/2 teaspoon turmeric\n",
      "- 1/2 teaspoon cayenne pepper (adjust to taste)\n",
      "- Salt and pepper to taste\n",
      "- Fresh cilantro, chopped (for garnish)\n",
      "- Cooked rice or naan bread (for serving)\n",
      "\n",
      "Instructions:\n",
      "1. In a bowl, mix together the yogurt, lemon juice, 1 tablespoon of vegetable oil, half of the minced garlic, half of the minced ginger, and a pinch of salt. Add the chicken pieces and stir to coat. Cover and marinate in the refrigerator for at least 1 hour, or overnight for best results.\n",
      "\n",
      "2. Preheat the oven to 400°F (200°C). Thread the marinated chicken onto skewers and place them on a baking sheet lined with aluminum foil. Bake for 20-25 minutes, or until the chicken is cooked through and slightly charred.\n",
      "\n",
      "3. In a large skillet, heat the remaining tablespoon of vegetable oil over medium heat. Add the chopped onion and cook until softened, about 5 minutes. Add the remaining garlic and ginger, and cook for another 2 minutes.\n",
      "\n",
      "4. Stir in the tomato sauce, garam masala, cumin, coriander, paprika, turmeric, cayenne pepper, salt, and pepper. Simmer for 10-15 minutes, stirring occasionally.\n",
      "\n",
      "5. Add the cooked chicken tikka to the skillet and simmer for an additional 5 minutes to allow the flavors to meld together.\n",
      "\n",
      "6. Serve the Chicken Tikka Masala over cooked rice or with naan bread. Garnish with chopped cilantro. Enjoy your delicious homemade Indian meal!\n",
      "\n",
      "Feel free to adjust the spice levels to suit your taste preferences. Enjoy your homemade Chicken Tikka Masala!To make a vegetarian version of Chicken Tikka Masala, we can replace the chicken with a suitable alternative. Here's how you can adapt the recipe:\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb of paneer or extra-firm tofu, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt (you can use dairy-free yogurt if preferred)\n",
      "- 2 tablespoons lemon juice\n",
      "- 2 tablespoons vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 3 cloves garlic, minced\n",
      "- 1 tablespoon ginger, minced\n",
      "- 1 can (14 oz) tomato sauce\n",
      "- 1 tablespoon garam masala\n",
      "- 1 teaspoon ground cumin\n",
      "- 1 teaspoon ground coriander\n",
      "- 1 teaspoon paprika\n",
      "- 1/2 teaspoon turmeric\n",
      "- 1/2 teaspoon cayenne pepper (adjust to taste)\n",
      "- Salt and pepper to taste\n",
      "- Fresh cilantro, chopped (for garnish)\n",
      "- Cooked rice or naan bread (for serving)\n",
      "\n",
      "Instructions:\n",
      "1. Instead of marinating chicken, marinate the paneer or tofu in the yogurt, lemon juice, 1 tablespoon of vegetable oil, half of the minced garlic, half of the minced ginger, and a pinch of salt. Cover and refrigerate for at least 1 hour, or overnight for best results.\n",
      "\n",
      "2. Follow the same steps to bake the marinated paneer or tofu on skewers in the preheated oven until slightly charred.\n",
      "\n",
      "3. In the skillet, proceed with cooking the onion, garlic, and ginger as per the original recipe.\n",
      "\n",
      "4. Add the tomato sauce, garam masala, cumin, coriander, paprika, turmeric, cayenne pepper, salt, and pepper. Simmer for 10-15 minutes.\n",
      "\n",
      "5. Add the baked paneer or tofu to the skillet and simmer for an additional 5 minutes to allow the flavors to meld together.\n",
      "\n",
      "6. Serve the Vegetarian Tikka Masala over cooked rice or with naan bread. Garnish with chopped cilantro.\n",
      "\n",
      "By making these simple swaps, you can enjoy a flavorful and satisfying Vegetarian Tikka Masala that stays true to the essence of the traditional recipe. Enjoy your meat-free Indian meal!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"To make a vegetarian version of Chicken Tikka Masala, we can replace the chicken with a suitable alternative. Here's how you can adapt the recipe:\\n\\nIngredients:\\n- 1 lb of paneer or extra-firm tofu, cut into bite-sized pieces\\n- 1 cup plain yogurt (you can use dairy-free yogurt if preferred)\\n- 2 tablespoons lemon juice\\n- 2 tablespoons vegetable oil\\n- 1 onion, finely chopped\\n- 3 cloves garlic, minced\\n- 1 tablespoon ginger, minced\\n- 1 can (14 oz) tomato sauce\\n- 1 tablespoon garam masala\\n- 1 teaspoon ground cumin\\n- 1 teaspoon ground coriander\\n- 1 teaspoon paprika\\n- 1/2 teaspoon turmeric\\n- 1/2 teaspoon cayenne pepper (adjust to taste)\\n- Salt and pepper to taste\\n- Fresh cilantro, chopped (for garnish)\\n- Cooked rice or naan bread (for serving)\\n\\nInstructions:\\n1. Instead of marinating chicken, marinate the paneer or tofu in the yogurt, lemon juice, 1 tablespoon of vegetable oil, half of the minced garlic, half of the minced ginger, and a pinch of salt. Cover and refrigerate for at least 1 hour, or overnight for best results.\\n\\n2. Follow the same steps to bake the marinated paneer or tofu on skewers in the preheated oven until slightly charred.\\n\\n3. In the skillet, proceed with cooking the onion, garlic, and ginger as per the original recipe.\\n\\n4. Add the tomato sauce, garam masala, cumin, coriander, paprika, turmeric, cayenne pepper, salt, and pepper. Simmer for 10-15 minutes.\\n\\n5. Add the baked paneer or tofu to the skillet and simmer for an additional 5 minutes to allow the flavors to meld together.\\n\\n6. Serve the Vegetarian Tikka Masala over cooked rice or with naan bread. Garnish with chopped cilantro.\\n\\nBy making these simple swaps, you can enjoy a flavorful and satisfying Vegetarian Tikka Masala that stays true to the essence of the traditional recipe. Enjoy your meat-free Indian meal!\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it\"),\n",
    "    (\"human\", \"{recipe}\")\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chain\n",
    "# chain에 context object를 넣어줌! (dictionary 형태)\n",
    "# veg_chain보다 먼저 실행됨\n",
    "# {\"recipe\": chef_chain} = LangChain 언어 = RunnableMap\n",
    "\n",
    "final_chain.invoke({\n",
    "    \"cuisine\": \"indian\"\n",
    "})\n",
    "\n",
    "# final_chain의 invoke 값은 chef_chain의 입력값인 cuisine으로 전달됨\n",
    "# chef_chain으로부터 얻은 결과는 reciope라는 key에 저장됨\n",
    "# recipe key의 값은 veg_chain의 입력값으로 전달됨\n",
    "    \n",
    "# veg_chain.invoke({\n",
    "#     \"recipe\": \"chatmodel\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
